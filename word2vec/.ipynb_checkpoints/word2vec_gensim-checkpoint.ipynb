{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e60e602b-b048-4706-8f36-5bb211fa61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 导入必要的库  \n",
    "import gensim  \n",
    "from gensim.models import Word2Vec  \n",
    "import numpy as np  \n",
    "import logging  \n",
    "\n",
    "# 设置日志  \n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ca25c8-9e84-4b3e-ad75-8c1464e50fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:35:14,607 : INFO : collecting all words and their counts\n",
      "2025-04-11 10:35:14,608 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2025-04-11 10:35:14,608 : INFO : collected 15 word types from a corpus of 16 raw words and 4 sentences\n",
      "2025-04-11 10:35:14,609 : INFO : Creating a fresh vocabulary\n",
      "2025-04-11 10:35:14,609 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 15 unique words (100.00% of original 15, drops 0)', 'datetime': '2025-04-11T10:35:14.609791', 'gensim': '4.3.1', 'python': '3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2025-04-11 10:35:14,610 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 16 word corpus (100.00% of original 16, drops 0)', 'datetime': '2025-04-11T10:35:14.610799', 'gensim': '4.3.1', 'python': '3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2025-04-11 10:35:14,611 : INFO : deleting the raw counts dictionary of 15 items\n",
      "2025-04-11 10:35:14,611 : INFO : sample=0.001 downsamples 15 most-common words\n",
      "2025-04-11 10:35:14,612 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2.1897609278942753 word corpus (13.7%% of prior 16)', 'datetime': '2025-04-11T10:35:14.612796', 'gensim': '4.3.1', 'python': '3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2025-04-11 10:35:14,614 : INFO : estimated required memory for 15 words and 100 dimensions: 19500 bytes\n",
      "2025-04-11 10:35:14,614 : INFO : resetting layer weights\n",
      "2025-04-11 10:35:14,615 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-11T10:35:14.615797', 'gensim': '4.3.1', 'python': '3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'build_vocab'}\n",
      "2025-04-11 10:35:14,616 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 15 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-04-11T10:35:14.616796', 'gensim': '4.3.1', 'python': '3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'train'}\n",
      "2025-04-11 10:35:14,620 : INFO : EPOCH 0: training on 16 raw words (2 effective words) took 0.0s, 1029 effective words/s\n",
      "2025-04-11 10:35:14,622 : INFO : EPOCH 1: training on 16 raw words (3 effective words) took 0.0s, 9251 effective words/s\n",
      "2025-04-11 10:35:14,624 : INFO : EPOCH 2: training on 16 raw words (1 effective words) took 0.0s, 2067 effective words/s\n",
      "2025-04-11 10:35:14,627 : INFO : EPOCH 3: training on 16 raw words (2 effective words) took 0.0s, 2957 effective words/s\n",
      "2025-04-11 10:35:14,628 : INFO : EPOCH 4: training on 16 raw words (2 effective words) took 0.0s, 16849 effective words/s\n",
      "2025-04-11 10:35:14,629 : INFO : Word2Vec lifecycle event {'msg': 'training on 80 raw words (10 effective words) took 0.0s, 772 effective words/s', 'datetime': '2025-04-11T10:35:14.629893', 'gensim': '4.3.1', 'python': '3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'train'}\n",
      "2025-04-11 10:35:14,629 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=15, vector_size=100, alpha=0.025>', 'datetime': '2025-04-11T10:35:14.629893', 'gensim': '4.3.1', 'python': '3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Skip-Gram模型训练完成。\n"
     ]
    }
   ],
   "source": [
    "# 2. 准备数据  \n",
    "# 示例数据集，您可以使用自己的数据集  \n",
    "sentences = [  \n",
    "    ['环境', '优雅', '美食', '好吃', '舒适'],  \n",
    "    ['餐厅', '氛围', '安静', '聚会'],  \n",
    "    ['蟑螂', '肮脏', '食物', '味道'],  \n",
    "    ['好吃', '美味', '佳肴'],  \n",
    "]  \n",
    "\n",
    "# 3. 训练 Word2Vec 模型（使用 Skip-Gram）  \n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=1)  \n",
    "\n",
    "# 输出模型训练完成的消息  \n",
    "print(\"Word2Vec Skip-Gram模型训练完成。\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac00505-c49a-404a-87b3-7cadcd858e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“环境”的词向量: [ 7.6966463e-03  9.1206422e-03  1.1355019e-03 -8.3250795e-03\n",
      "  8.4250160e-03 -3.6962307e-03  5.7421732e-03  4.3915794e-03\n",
      "  9.6899448e-03 -9.2934975e-03  9.2084054e-03 -9.2815282e-03\n",
      " -6.9077122e-03 -9.1021946e-03 -5.5471100e-03  7.3688962e-03\n",
      "  9.1644777e-03 -3.3253515e-03  3.7230505e-03 -3.6252034e-03\n",
      "  7.8814710e-03  5.8668759e-03  2.0861626e-07 -3.6286747e-03\n",
      " -7.2243060e-03  4.7686161e-03  1.4529788e-03 -2.6131857e-03\n",
      "  7.8378068e-03 -4.0496145e-03 -9.1489861e-03 -2.2554707e-03\n",
      "  1.2514711e-04 -6.6392552e-03 -5.4866159e-03 -8.4997769e-03\n",
      "  9.2298733e-03  7.4240281e-03 -2.9524326e-04  7.3676636e-03\n",
      "  7.9507884e-03 -7.8357337e-04  6.6120909e-03  3.7675237e-03\n",
      "  5.0768424e-03  7.2529912e-03 -4.7393893e-03 -2.1855331e-03\n",
      "  8.7312341e-04  4.2362059e-03  3.3043313e-03  5.0958274e-03\n",
      "  4.5864857e-03 -8.4385090e-03 -3.1838394e-03 -7.2367596e-03\n",
      "  9.6814223e-03  5.0065992e-03  1.7084122e-04  4.1129780e-03\n",
      " -7.6561309e-03 -6.2946510e-03  3.0763936e-03  6.5346383e-03\n",
      "  3.9498745e-03  6.0180221e-03 -1.9861318e-03 -3.3451295e-03\n",
      "  2.0717025e-04 -3.1943608e-03 -5.5169044e-03 -7.7885604e-03\n",
      "  6.5355431e-03 -1.0903371e-03 -1.8908798e-03 -7.8047751e-03\n",
      "  9.3375733e-03  8.6814165e-04  1.7696369e-03  2.4916660e-03\n",
      " -7.3859929e-03  1.6388226e-03  2.9765631e-03 -8.5670296e-03\n",
      "  4.9558021e-03  2.4334085e-03  7.4979127e-03  5.0442982e-03\n",
      " -3.0317164e-03 -7.1629370e-03  7.0962133e-03  1.9015349e-03\n",
      "  5.1992359e-03  6.3811089e-03  1.9122792e-03 -6.1276113e-03\n",
      " -6.2966346e-06  8.2682976e-03 -6.0985480e-03  9.4382809e-03]\n",
      "形状: (100,)\n"
     ]
    }
   ],
   "source": [
    "# 4. 输出“环境”的词向量及其形状  \n",
    "vector_environment = word2vec_model.wv['环境']  \n",
    "print(\"“环境”的词向量:\", vector_environment)  \n",
    "print(\"形状:\", vector_environment.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49bc2676-490e-4010-901e-36ddba3ffcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "与“好吃”最接近的3个词: [('氛围', 0.21617145836353302), ('美食', 0.0931011214852333), ('聚会', 0.09291718155145645)]\n"
     ]
    }
   ],
   "source": [
    "# 5. 输出与“好吃”语义最接近的3个词  \n",
    "similar_words = word2vec_model.wv.most_similar('好吃', topn=3)  \n",
    "print(\"与“好吃”最接近的3个词:\", similar_words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "161ea780-7688-415f-bf7d-c9361086f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“好吃”和“美味”的相似度: -0.052346736\n",
      "“好吃”和“蟑螂”的相似度: 0.016134689\n"
     ]
    }
   ],
   "source": [
    "# 6. 计算相似度  \n",
    "similarity_delicious_delicacy = word2vec_model.wv.similarity('好吃', '美味')  \n",
    "similarity_delicious_cockroach = word2vec_model.wv.similarity('好吃', '蟑螂')  \n",
    "\n",
    "print(\"“好吃”和“美味”的相似度:\", similarity_delicious_delicacy)  \n",
    "print(\"“好吃”和“蟑螂”的相似度:\", similarity_delicious_cockroach)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe98d046-3588-4a4c-b407-7d7cdefce763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“餐厅+聚会-安静=？”的结果: [('舒适', 0.09841553866863251)]\n"
     ]
    }
   ],
   "source": [
    "# 7. 执行向量运算“餐厅+聚会-安静=？”  \n",
    "result = word2vec_model.wv.most_similar(positive=['餐厅', '聚会'], negative=['安静'], topn=1)  \n",
    "print(\"“餐厅+聚会-安静=？”的结果:\", result)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
