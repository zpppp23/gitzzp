{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d56be828-6a99-4c57-97ae-44bb62ba1bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\27298\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.426 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用frequency特征的结果:\n",
      "邮件_files/151.txt分类情况: 垃圾邮件\n",
      "邮件_files/152.txt分类情况: 垃圾邮件\n",
      "邮件_files/153.txt分类情况: 垃圾邮件\n",
      "邮件_files/154.txt分类情况: 垃圾邮件\n",
      "邮件_files/155.txt分类情况: 普通邮件\n",
      "\n",
      "使用TF-IDF特征的结果:\n",
      "邮件_files/151.txt分类情况: 垃圾邮件\n",
      "邮件_files/152.txt分类情况: 垃圾邮件\n",
      "邮件_files/153.txt分类情况: 垃圾邮件\n",
      "邮件_files/154.txt分类情况: 垃圾邮件\n",
      "邮件_files/155.txt分类情况: 垃圾邮件\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from jieba import cut\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "class EmailClassifier:\n",
    "    def __init__(self, feature_type='frequency', top_num=100):\n",
    "        \"\"\"\n",
    "        初始化分类器\n",
    "        :param feature_type: 特征类型，'frequency'(高频词)或'tfidf'(TF-IDF)\n",
    "        :param top_num: 特征数量\n",
    "        \"\"\"\n",
    "        self.feature_type = feature_type\n",
    "        self.top_num = top_num\n",
    "        self.model = MultinomialNB()\n",
    "        self.top_words = None\n",
    "        self.vectorizer = None\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        \"\"\"清洗文本\"\"\"\n",
    "        text = re.sub(r'[.【】0-9、——。，！~\\*]', '', text)\n",
    "        words = cut(text)\n",
    "        return [word for word in words if len(word) > 1]\n",
    "\n",
    "    def get_words(self, filename):\n",
    "        \"\"\"读取文件并返回清洗后的词语列表\"\"\"\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        return self.clean_text(text)\n",
    "\n",
    "    def get_texts(self, filenames):\n",
    "        \"\"\"获取所有文件的文本内容\"\"\"\n",
    "        texts = []\n",
    "        for filename in filenames:\n",
    "            words = self.get_words(filename)\n",
    "            texts.append(' '.join(words))  # 用空格连接词语\n",
    "        return texts\n",
    "\n",
    "    def get_top_words(self, filenames):\n",
    "        \"\"\"获取高频词特征\"\"\"\n",
    "        all_words = []\n",
    "        for filename in filenames:\n",
    "            all_words.append(self.get_words(filename))\n",
    "\n",
    "        # 统计词频\n",
    "        freq = Counter(chain(*all_words))\n",
    "        return [i[0] for i in freq.most_common(self.top_num)]\n",
    "\n",
    "    def extract_features(self, filenames, fit=False):\n",
    "        \"\"\"提取特征\"\"\"\n",
    "        texts = self.get_texts(filenames)\n",
    "\n",
    "        if self.feature_type == 'frequency':\n",
    "            # 高频词特征\n",
    "            if fit or self.top_words is None:\n",
    "                self.top_words = self.get_top_words(filenames)\n",
    "\n",
    "            features = []\n",
    "            for text in texts:\n",
    "                words = text.split()\n",
    "                word_map = list(map(lambda word: words.count(word), self.top_words))\n",
    "                features.append(word_map)\n",
    "            return np.array(features)\n",
    "\n",
    "        elif self.feature_type == 'TF-IDF':\n",
    "            # TF-IDF特征\n",
    "            if fit:\n",
    "                self.vectorizer = TfidfVectorizer(\n",
    "                    tokenizer=self.clean_text,\n",
    "                    max_features=self.top_num,\n",
    "                    token_pattern=None\n",
    "                )\n",
    "                features = self.vectorizer.fit_transform(texts)\n",
    "            else:\n",
    "                features = self.vectorizer.transform(texts)\n",
    "            return features.toarray()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"feature_type必须是'frequency'或'TF-IDF'\")\n",
    "\n",
    "    def train(self, train_files):\n",
    "        \"\"\"训练模型\"\"\"\n",
    "        # 提取特征\n",
    "        train_features = self.extract_features(train_files, fit=True)\n",
    "\n",
    "        # 0-126.txt为垃圾邮件标记为1；127-151.txt为普通邮件标记为0\n",
    "        train_labels = np.array([1] * 127 + [0] * 24)\n",
    "\n",
    "        # 训练模型\n",
    "        self.model.fit(train_features, train_labels)\n",
    "\n",
    "    def predict(self, filename):\n",
    "        \"\"\"预测单个文件\"\"\"\n",
    "        # 提取特征\n",
    "        features = self.extract_features([filename])\n",
    "\n",
    "        # 预测结果\n",
    "        result = self.model.predict(features)\n",
    "        return '垃圾邮件' if result == 1 else '普通邮件'\n",
    "\n",
    "    def evaluate(self, test_files):\n",
    "        \"\"\"评估多个测试文件\"\"\"\n",
    "        results = {}\n",
    "        for test_file in test_files:\n",
    "            results[test_file] = self.predict(test_file)\n",
    "        return results\n",
    "\n",
    "\n",
    "def main(feature_type='frequency'):\n",
    "    # 训练文件列表\n",
    "    train_files = [f'邮件_files/{i}.txt' for i in range(151)]\n",
    "    # 测试文件列表\n",
    "    test_files = [f'邮件_files/{i}.txt' for i in range(151, 156)]\n",
    "\n",
    "    # 创建并训练分类器\n",
    "    classifier = EmailClassifier(feature_type=feature_type, top_num=100)\n",
    "    classifier.train(train_files)\n",
    "\n",
    "    # 评估测试文件\n",
    "    results = classifier.evaluate(test_files)\n",
    "\n",
    "    # 打印结果\n",
    "    print(f\"\\n使用{feature_type}特征的结果:\")\n",
    "    for filename, prediction in results.items():\n",
    "        print(f\"{filename}分类情况: {prediction}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 使用高频词特征\n",
    "    main(feature_type='frequency')\n",
    "\n",
    "    # 使用TF-IDF特征\n",
    "    main(feature_type='TF-IDF')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
